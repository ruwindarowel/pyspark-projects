# This file is automatically @generated by Poetry 2.2.1 and should not be changed by hand.

[[package]]
name = "py4j"
version = "0.10.9.9"
description = "Enables Python programs to dynamically access arbitrary Java objects"
optional = false
python-versions = "*"
groups = ["main"]
files = [
    {file = "py4j-0.10.9.9-py2.py3-none-any.whl", hash = "sha256:c7c26e4158defb37b0bb124933163641a2ff6e3a3913f7811b0ddbe07ed61533"},
    {file = "py4j-0.10.9.9.tar.gz", hash = "sha256:f694cad19efa5bd1dee4f3e5270eb406613c974394035e5bfc4ec1aba870b879"},
]

[[package]]
name = "pyspark"
version = "4.1.0"
description = "Apache Spark Python API"
optional = false
python-versions = ">=3.10"
groups = ["main"]
files = [
    {file = "pyspark-4.1.0.tar.gz", hash = "sha256:09c714ada88dfac3e1213c066617c6f473c1e22fbe279855028f77e12434147d"},
]

[package.dependencies]
py4j = ">=0.10.9.7,<0.10.9.10"

[package.extras]
connect = ["googleapis-common-protos (>=1.71.0)", "grpcio (>=1.76.0)", "grpcio-status (>=1.76.0)", "numpy (>=1.21)", "pandas (>=2.2.0)", "pyarrow (>=15.0.0)", "zstandard (>=0.25.0)"]
ml = ["numpy (>=1.21)"]
mllib = ["numpy (>=1.21)"]
pandas-on-spark = ["numpy (>=1.21)", "pandas (>=2.2.0)", "pyarrow (>=15.0.0)"]
pipelines = ["googleapis-common-protos (>=1.71.0)", "grpcio (>=1.76.0)", "grpcio-status (>=1.76.0)", "numpy (>=1.21)", "pandas (>=2.2.0)", "pyarrow (>=15.0.0)", "pyyaml (>=3.11)", "zstandard (>=0.25.0)"]
sql = ["numpy (>=1.21)", "pandas (>=2.2.0)", "pyarrow (>=15.0.0)"]

[metadata]
lock-version = "2.1"
python-versions = ">=3.10"
content-hash = "c243b7a4f84bd2be7cd630b14426a912e15d4dddde220708644ffa35760f82fa"
